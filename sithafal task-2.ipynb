{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the Hugging Face pipeline for Question Answering\n",
    "qa_pipeline = pipeline(\"question-answering\")\n",
    "\n",
    "# Initialize Embedding Model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Function to Crawl and Scrape Website Content\n",
    "def scrape_website(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        # Extract text from paragraphs\n",
    "        paragraphs = [p.get_text() for p in soup.find_all(\"p\")]\n",
    "        return \" \".join(paragraphs)\n",
    "    else:\n",
    "        print(f\"Failed to fetch {url}. Status code: {response.status_code}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to Segment Content into Chunks\n",
    "def segment_content(text, max_chunk_size=500):\n",
    "    words = text.split()\n",
    "    chunks = [\n",
    "        \" \".join(words[i:i + max_chunk_size])\n",
    "        for i in range(0, len(words), max_chunk_size)\n",
    "    ]\n",
    "    return chunks\n",
    "\n",
    "# Function to Store Embeddings in FAISS\n",
    "def store_embeddings(urls):\n",
    "    # FAISS index setup\n",
    "    dimension = 384  # for the all-MiniLM-L6-v2 model\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    ids = []\n",
    "    embeddings = []\n",
    "    metadata = []\n",
    "    \n",
    "    for url in urls:\n",
    "        print(f\"Scraping: {url}\")\n",
    "        content = scrape_website(url)\n",
    "        if content:\n",
    "            print(\"Segmenting content...\")\n",
    "            chunks = segment_content(content)\n",
    "            print(\"Generating embeddings...\")\n",
    "            chunk_embeddings = embedding_model.encode(chunks)\n",
    "            for i, chunk_embedding in enumerate(chunk_embeddings):\n",
    "                index.add(np.array([chunk_embedding]).astype(\"float32\"))\n",
    "                ids.append(f\"{url}-{i}\")\n",
    "                embeddings.append(chunk_embedding)\n",
    "                metadata.append({\"url\": url, \"chunk_id\": i, \"text\": chunks[i]})\n",
    "    return index, ids, embeddings, metadata\n",
    "\n",
    "# Function to Perform Query and Generate Response\n",
    "def query_pipeline(user_query, index, metadata):\n",
    "    print(\"Generating query embedding...\")\n",
    "    query_embedding = embedding_model.encode([user_query])\n",
    "\n",
    "    print(\"Searching in FAISS...\")\n",
    "    D, I = index.search(np.array(query_embedding).astype(\"float32\"), k=5)\n",
    "\n",
    "    # Construct context for QA model\n",
    "    context = \"\\n\".join(\n",
    "        [f\"Chunk {i+1}: {metadata[idx]['text']}\" for i, idx in enumerate(I[0])]\n",
    "    )\n",
    "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {user_query}\"\n",
    "\n",
    "    print(\"Querying Hugging Face QA model...\")\n",
    "    response = qa_pipeline(question=user_query, context=context)\n",
    "    return response[\"answer\"]\n",
    "\n",
    "# Main Script\n",
    "if __name__ == \"__main__\":\n",
    "    # URLs to process\n",
    "    urls = [\n",
    "        \"https://www.uchicago.edu/\",\n",
    "        \"https://www.washington.edu/\",\n",
    "        \"https://www.stanford.edu/\",\n",
    "        \"https://und.edu/\"\n",
    "    ]\n",
    "\n",
    "    # Step 1: Crawl, Embed, and Store in FAISS\n",
    "    print(\"Starting data ingestion...\")\n",
    "    index, ids, embeddings, metadata = store_embeddings(urls)\n",
    "\n",
    "    # Step 2: Query the System\n",
    "    print(\"Ready for user queries.\")\n",
    "    while True:\n",
    "        query = input(\"\\nEnter your question (or 'exit' to quit): \")\n",
    "        if query.lower() == \"exit\":\n",
    "            break\n",
    "        response = query_pipeline(query, index, metadata)\n",
    "        print(\"\\nResponse:\")\n",
    "        print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d1dcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
